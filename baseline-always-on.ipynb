{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76e6e013",
   "metadata": {},
   "source": [
    "# Always-On NER Baseline\n",
    "\n",
    "This notebook implements the \"always-on\" baseline for near real-time Named Entity Recognition (NER). In this approach, we run NER on every token as it arrives, simulating a scenario where we have no selective inference strategy.\n",
    "\n",
    "This is the most computationally expensive approach, but it gives us the earliest possible detection of entities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff271aac",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45a38814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in ./.venv/lib/python3.13/site-packages (3.6.0)\n",
      "Requirement already satisfied: transformers in ./.venv/lib/python3.13/site-packages (4.52.4)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.13/site-packages (from datasets) (2.3.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./.venv/lib/python3.13/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.venv/lib/python3.13/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.13/site-packages (from datasets) (2.3.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in ./.venv/lib/python3.13/site-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./.venv/lib/python3.13/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in ./.venv/lib/python3.13/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./.venv/lib/python3.13/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in ./.venv/lib/python3.13/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in ./.venv/lib/python3.13/site-packages (from datasets) (0.33.0)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.13/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.13/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./.venv/lib/python3.13/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.13/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.13/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.24.0->datasets) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.5.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in ./.venv/lib/python3.13/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (2025.6.15)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.24.0->datasets) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.5.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in ./.venv/lib/python3.13/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (2025.6.15)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58d255bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierre/projects/uzh_repos/aml2025-group-17/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import asyncio\n",
    "import time\n",
    "import random\n",
    "import multiprocessing as mp\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78daf5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"./src/\")\n",
    "from utils import convert_predictions\n",
    "from streaming import process_ontonotes_example, stream_sentence\n",
    "from metrics import Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4ec4173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import metrics\n",
    "from importlib import reload\n",
    "reload(metrics)\n",
    "\n",
    "from metrics import Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ffa1c2",
   "metadata": {},
   "source": [
    "## 2. Load OntoNotes Dataset\n",
    "\n",
    "We'll use the OntoNotes 5.0 dataset, which contains texts from various genres with named entity annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb372455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded with splits: dict_keys(['train', 'validation', 'test'])\n",
      "Train set: 10539 examples\n",
      "Validation set: 1370 examples\n",
      "Test set: 1200 examples\n"
     ]
    }
   ],
   "source": [
    "# Load the English portion of OntoNotes 5.0\n",
    "ontonotes = load_dataset(\n",
    "    \"conll2012_ontonotesv5\",\n",
    "    \"english_v12\",\n",
    "    cache_dir=\"./dataset/ontonotes\",\n",
    ")\n",
    "print(f\"Dataset loaded with splits: {ontonotes.keys()}\")\n",
    "\n",
    "# Get basic statistics for each split\n",
    "for split_name in ontonotes.keys():\n",
    "    print(f\"{split_name.capitalize()} set: {len(ontonotes[split_name])} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4f4fa0",
   "metadata": {},
   "source": [
    "## 3. Set Up NER Model\n",
    "\n",
    "We'll use a pre-trained transformer model for NER. For this baseline, we'll use a BERT-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0ee9163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text: John Smith works at Microsoft in Seattle.\n",
      "NER pipeline output: [{'entity_group': 'PER', 'score': np.float32(0.9996886), 'word': 'John Smith', 'start': 0, 'end': 10}, {'entity_group': 'ORG', 'score': np.float32(0.9989378), 'word': 'Microsoft', 'start': 20, 'end': 29}, {'entity_group': 'LOC', 'score': np.float32(0.9988439), 'word': 'Seattle', 'start': 33, 'end': 40}]\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained NER model\n",
    "model_name = \"dslim/bert-base-NER\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "# Create NER pipeline\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "\n",
    "# Wrapper function for NER that takes tokens and returns predictions\n",
    "def run_ner_on_tokens(tokens):\n",
    "    \"\"\"Run NER on a list of tokens.\"\"\"\n",
    "    text = \" \".join(tokens)\n",
    "    pipeline_output = ner_pipeline(text)\n",
    "    return pipeline_output\n",
    "\n",
    "# NEW: Create a worker function that can be pickled for multiprocessing\n",
    "def create_ner_worker():\n",
    "    \"\"\"Create a NER pipeline in a worker process.\"\"\"\n",
    "    from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "    model_name = \"dslim/bert-base-NER\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "    return pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "\n",
    "# Global variable to store the pipeline in worker processes\n",
    "_worker_pipeline = None\n",
    "\n",
    "def init_worker():\n",
    "    \"\"\"Initialize the NER pipeline in each worker process.\"\"\"\n",
    "    global _worker_pipeline\n",
    "    _worker_pipeline = create_ner_worker()\n",
    "\n",
    "def worker_run_ner(tokens):\n",
    "    \"\"\"Worker function that runs NER on tokens.\"\"\"\n",
    "    global _worker_pipeline\n",
    "    text = \" \".join(tokens)\n",
    "    return _worker_pipeline(text)\n",
    "\n",
    "# Test NER model on a sample sentence\n",
    "sample_text = \"John Smith works at Microsoft in Seattle.\"\n",
    "print(f\"Sample text: {sample_text}\")\n",
    "test_output = ner_pipeline(sample_text)\n",
    "print(f\"NER pipeline output: {test_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2896f89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['John', 'Smith', 'works', 'at', 'Microsoft', 'in', 'Seattle']\n",
      "Converted BIO tags: ['B-PER', 'I-PER', 'O', 'O', 'B-ORG', 'O', 'B-LOC']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Removing punctuation to prevent mismatches and splitting the sample text into tokens\n",
    "tokens = re.sub(r\"[.,?!]+\", \"\", sample_text).split(\" \")\n",
    "\n",
    "bio_tags = convert_predictions(tokens, test_output)\n",
    "print(f\"Tokens: {tokens}\")\n",
    "print(f\"Converted BIO tags: {bio_tags}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "699aac95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics:\n",
      "Total NER invocations: 2\n",
      "Avg TTFD: 0.67\n",
      "Entity Type          TP         TN         FP (#B-/I-MISC)      FN        \n",
      "----------------------------------------------------------------------\n",
      "O                    N/A        3          0                    N/A       \n",
      "B-PERSON             0          N/A        0                    0         \n",
      "I-PERSON             0          N/A        0                    0         \n",
      "B-NORP               0          N/A        0                    0         \n",
      "I-NORP               0          N/A        0                    0         \n",
      "B-FAC                0          N/A        0                    0         \n",
      "I-FAC                0          N/A        0                    0         \n",
      "B-ORG                1          N/A        0                    0         \n",
      "I-ORG                0          N/A        0                    0         \n",
      "B-GPE                0          N/A        0                    0         \n",
      "I-GPE                0          N/A        0                    0         \n",
      "B-LOC                1          N/A        0                    0         \n",
      "I-LOC                0          N/A        0                    0         \n",
      "B-PRODUCT            0          N/A        0                    0         \n",
      "I-PRODUCT            0          N/A        0                    0         \n",
      "B-DATE               0          N/A        0                    0         \n",
      "I-DATE               0          N/A        0                    0         \n",
      "B-TIME               0          N/A        0                    0         \n",
      "I-TIME               0          N/A        0                    0         \n",
      "B-PERCENT            0          N/A        0                    0         \n",
      "I-PERCENT            0          N/A        0                    0         \n",
      "B-MONEY              0          N/A        0                    0         \n",
      "I-MONEY              0          N/A        0                    0         \n",
      "B-QUANTITY           0          N/A        0                    0         \n",
      "I-QUANTITY           0          N/A        0                    0         \n",
      "B-ORDINAL            0          N/A        0                    0         \n",
      "I-ORDINAL            0          N/A        0                    0         \n",
      "B-CARDINAL           0          N/A        0                    0         \n",
      "I-CARDINAL           0          N/A        0                    0         \n",
      "B-EVENT              0          N/A        0                    0         \n",
      "I-EVENT              0          N/A        0                    0         \n",
      "B-WORK_OF_ART        0          N/A        0                    0         \n",
      "I-WORK_OF_ART        0          N/A        0                    0         \n",
      "B-LAW                0          N/A        0                    0         \n",
      "I-LAW                0          N/A        0                    0         \n",
      "B-LANGUAGE           0          N/A        0                    0         \n",
      "I-LANGUAGE           0          N/A        0                    0         \n",
      "Total                4          3          0 (0/0)              0         \n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_metrics = Metrics()\n",
    "# Simulate a prediction for the sample text\n",
    "\n",
    "test_metrics.evaluate_metrics((tokens, bio_tags), [bio_tags[0:2], bio_tags])\n",
    "test_metrics.print_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a362cedf",
   "metadata": {},
   "source": [
    "## 4. Implement Always-On Baseline with Async Streams\n",
    "\n",
    "Now we'll implement the always-on baseline using our async stream generator. This approach runs NER on every token as it arrives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27a013e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sentence: (['Dear', 'viewers', ',', 'the', 'China', 'News', 'program', 'will', 'end', 'here', '.'], ['O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O'])\n",
      "Run always output: [((['Dear', 'viewers', ',', 'the', 'China', 'News', 'program', 'will', 'end', 'here', '.'], ['O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O']), [(['Dear'], []), (['Dear', 'viewers'], []), (['Dear', 'viewers', ','], []), (['Dear', 'viewers', ',', 'the'], []), (['Dear', 'viewers', ',', 'the', 'China'], [{'entity_group': 'LOC', 'score': np.float32(0.9609133), 'word': 'China', 'start': 19, 'end': 24}]), (['Dear', 'viewers', ',', 'the', 'China', 'News'], [{'entity_group': 'ORG', 'score': np.float32(0.9969154), 'word': 'China News', 'start': 19, 'end': 29}]), (['Dear', 'viewers', ',', 'the', 'China', 'News', 'program'], [{'entity_group': 'ORG', 'score': np.float32(0.95669866), 'word': 'China News', 'start': 19, 'end': 29}]), (['Dear', 'viewers', ',', 'the', 'China', 'News', 'program', 'will'], [{'entity_group': 'ORG', 'score': np.float32(0.9803317), 'word': 'China News', 'start': 19, 'end': 29}]), (['Dear', 'viewers', ',', 'the', 'China', 'News', 'program', 'will', 'end'], [{'entity_group': 'ORG', 'score': np.float32(0.96724105), 'word': 'China News', 'start': 19, 'end': 29}]), (['Dear', 'viewers', ',', 'the', 'China', 'News', 'program', 'will', 'end', 'here'], [{'entity_group': 'ORG', 'score': np.float32(0.95806026), 'word': 'China News', 'start': 19, 'end': 29}]), (['Dear', 'viewers', ',', 'the', 'China', 'News', 'program', 'will', 'end', 'here', '.'], [{'entity_group': 'ORG', 'score': np.float32(0.9446998), 'word': 'China News', 'start': 19, 'end': 29}])])]\n",
      "Run always output BIO: [[(['Dear'], ['O']), (['Dear', 'viewers'], ['O', 'O']), (['Dear', 'viewers', ','], ['O', 'O', 'O']), (['Dear', 'viewers', ',', 'the'], ['O', 'O', 'O', 'O']), (['Dear', 'viewers', ',', 'the', 'China'], ['O', 'O', 'O', 'O', 'B-LOC']), (['Dear', 'viewers', ',', 'the', 'China', 'News'], ['O', 'O', 'O', 'O', 'B-ORG', 'I-ORG']), (['Dear', 'viewers', ',', 'the', 'China', 'News', 'program'], ['O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O']), (['Dear', 'viewers', ',', 'the', 'China', 'News', 'program', 'will'], ['O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O']), (['Dear', 'viewers', ',', 'the', 'China', 'News', 'program', 'will', 'end'], ['O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O']), (['Dear', 'viewers', ',', 'the', 'China', 'News', 'program', 'will', 'end', 'here'], ['O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O']), (['Dear', 'viewers', ',', 'the', 'China', 'News', 'program', 'will', 'end', 'here', '.'], ['O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O'])]]\n",
      "Run always output: [((['Dear', 'viewers', ',', 'the', 'China', 'News', 'program', 'will', 'end', 'here', '.'], ['O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O']), [(['Dear'], []), (['Dear', 'viewers'], []), (['Dear', 'viewers', ','], []), (['Dear', 'viewers', ',', 'the'], []), (['Dear', 'viewers', ',', 'the', 'China'], [{'entity_group': 'LOC', 'score': np.float32(0.9609133), 'word': 'China', 'start': 19, 'end': 24}]), (['Dear', 'viewers', ',', 'the', 'China', 'News'], [{'entity_group': 'ORG', 'score': np.float32(0.9969154), 'word': 'China News', 'start': 19, 'end': 29}]), (['Dear', 'viewers', ',', 'the', 'China', 'News', 'program'], [{'entity_group': 'ORG', 'score': np.float32(0.95669866), 'word': 'China News', 'start': 19, 'end': 29}]), (['Dear', 'viewers', ',', 'the', 'China', 'News', 'program', 'will'], [{'entity_group': 'ORG', 'score': np.float32(0.9803317), 'word': 'China News', 'start': 19, 'end': 29}]), (['Dear', 'viewers', ',', 'the', 'China', 'News', 'program', 'will', 'end'], [{'entity_group': 'ORG', 'score': np.float32(0.96724105), 'word': 'China News', 'start': 19, 'end': 29}]), (['Dear', 'viewers', ',', 'the', 'China', 'News', 'program', 'will', 'end', 'here'], [{'entity_group': 'ORG', 'score': np.float32(0.95806026), 'word': 'China News', 'start': 19, 'end': 29}]), (['Dear', 'viewers', ',', 'the', 'China', 'News', 'program', 'will', 'end', 'here', '.'], [{'entity_group': 'ORG', 'score': np.float32(0.9446998), 'word': 'China News', 'start': 19, 'end': 29}])])]\n",
      "Run always output BIO: [[(['Dear'], ['O']), (['Dear', 'viewers'], ['O', 'O']), (['Dear', 'viewers', ','], ['O', 'O', 'O']), (['Dear', 'viewers', ',', 'the'], ['O', 'O', 'O', 'O']), (['Dear', 'viewers', ',', 'the', 'China'], ['O', 'O', 'O', 'O', 'B-LOC']), (['Dear', 'viewers', ',', 'the', 'China', 'News'], ['O', 'O', 'O', 'O', 'B-ORG', 'I-ORG']), (['Dear', 'viewers', ',', 'the', 'China', 'News', 'program'], ['O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O']), (['Dear', 'viewers', ',', 'the', 'China', 'News', 'program', 'will'], ['O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O']), (['Dear', 'viewers', ',', 'the', 'China', 'News', 'program', 'will', 'end'], ['O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O']), (['Dear', 'viewers', ',', 'the', 'China', 'News', 'program', 'will', 'end', 'here'], ['O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O']), (['Dear', 'viewers', ',', 'the', 'China', 'News', 'program', 'will', 'end', 'here', '.'], ['O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O'])]]\n"
     ]
    }
   ],
   "source": [
    "async def run_always_on(sentences):\n",
    "    \"\"\"Run NER on a list of sentences.\"\"\"\n",
    "    results = []\n",
    "    for sentence in sentences:\n",
    "        sentence, true_labels = sentence\n",
    "        buffer = []\n",
    "        sentence_results = []\n",
    "        async for token, label in stream_sentence((sentence, true_labels)):\n",
    "            buffer.append(token)\n",
    "            pipeline_output = run_ner_on_tokens(buffer)\n",
    "            sentence_results.append((buffer.copy(), pipeline_output))\n",
    "        results.append(((sentence, true_labels), sentence_results))\n",
    "    return results\n",
    "\n",
    "test_split = ontonotes[\"test\"]\n",
    "test_example = test_split[0]\n",
    "test_sentences = process_ontonotes_example(test_example)\n",
    "test_sentence = test_sentences[3]\n",
    "print(f\"Test sentence: {test_sentence}\")\n",
    "run_always_output = await run_always_on([test_sentence])\n",
    "print(f\"Run always output: {run_always_output}\")\n",
    "bio_always_output = [list(map(lambda curr: (curr[0], convert_predictions(curr[0], curr[1])), predictions)) for _, predictions in run_always_output]\n",
    "# bio_always_output = list(map(lambda curr: (curr[0], convert_predictions(curr[0], curr[1])), run_always_output))\n",
    "print(f\"Run always output BIO: {bio_always_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be417d5f",
   "metadata": {},
   "source": [
    "Previous example uses the truth values, therefore preprocessing the examples using `process_ontonotes_example`. Below we do the same thing without using the ground truth labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f173621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sentence: ['Dear', 'viewers', ',', 'the', 'China', 'News', 'program', 'will', 'end', 'here', '.']\n",
      "Run always output: [((['Dear', 'viewers', ',', 'the', 'China', 'News', 'program', 'will', 'end', 'here', '.'], None), [(['Dear'], []), (['Dear', 'viewers'], []), (['Dear', 'viewers', ','], []), (['Dear', 'viewers', ',', 'the'], []), (['Dear', 'viewers', ',', 'the', 'China'], [{'entity_group': 'LOC', 'score': np.float32(0.9609133), 'word': 'China', 'start': 19, 'end': 24}]), (['Dear', 'viewers', ',', 'the', 'China', 'News'], [{'entity_group': 'ORG', 'score': np.float32(0.9969154), 'word': 'China News', 'start': 19, 'end': 29}]), (['Dear', 'viewers', ',', 'the', 'China', 'News', 'program'], [{'entity_group': 'ORG', 'score': np.float32(0.95669866), 'word': 'China News', 'start': 19, 'end': 29}]), (['Dear', 'viewers', ',', 'the', 'China', 'News', 'program', 'will'], [{'entity_group': 'ORG', 'score': np.float32(0.9803317), 'word': 'China News', 'start': 19, 'end': 29}]), (['Dear', 'viewers', ',', 'the', 'China', 'News', 'program', 'will', 'end'], [{'entity_group': 'ORG', 'score': np.float32(0.96724105), 'word': 'China News', 'start': 19, 'end': 29}]), (['Dear', 'viewers', ',', 'the', 'China', 'News', 'program', 'will', 'end', 'here'], [{'entity_group': 'ORG', 'score': np.float32(0.95806026), 'word': 'China News', 'start': 19, 'end': 29}]), (['Dear', 'viewers', ',', 'the', 'China', 'News', 'program', 'will', 'end', 'here', '.'], [{'entity_group': 'ORG', 'score': np.float32(0.9446998), 'word': 'China News', 'start': 19, 'end': 29}])])]\n",
      "Run always output BIO: [[(['Dear'], ['O']), (['Dear', 'viewers'], ['O', 'O']), (['Dear', 'viewers', ','], ['O', 'O', 'O']), (['Dear', 'viewers', ',', 'the'], ['O', 'O', 'O', 'O']), (['Dear', 'viewers', ',', 'the', 'China'], ['O', 'O', 'O', 'O', 'B-LOC']), (['Dear', 'viewers', ',', 'the', 'China', 'News'], ['O', 'O', 'O', 'O', 'B-ORG', 'I-ORG']), (['Dear', 'viewers', ',', 'the', 'China', 'News', 'program'], ['O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O']), (['Dear', 'viewers', ',', 'the', 'China', 'News', 'program', 'will'], ['O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O']), (['Dear', 'viewers', ',', 'the', 'China', 'News', 'program', 'will', 'end'], ['O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O']), (['Dear', 'viewers', ',', 'the', 'China', 'News', 'program', 'will', 'end', 'here'], ['O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O']), (['Dear', 'viewers', ',', 'the', 'China', 'News', 'program', 'will', 'end', 'here', '.'], ['O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O'])]]\n"
     ]
    }
   ],
   "source": [
    "test_sentence = test_split[0]['sentences'][3]['words']\n",
    "print(f\"Test sentence: {test_sentence}\")\n",
    "run_always_output = await run_always_on([(test_sentence, None)])\n",
    "print(f\"Run always output: {run_always_output}\")\n",
    "bio_always_output = [list(map(lambda curr: (curr[0], convert_predictions(curr[0], curr[1])), predictions)) for _, predictions in run_always_output]\n",
    "print(f\"Run always output BIO: {bio_always_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39ce97e",
   "metadata": {},
   "source": [
    "## 5. Running always-on baseline over test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "371335fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 examples from the test set.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:03<00:00, 63.49s/it]\n",
      "100%|██████████| 1/1 [01:03<00:00, 63.49s/it]\n"
     ]
    }
   ],
   "source": [
    "always_on_metrics = Metrics()\n",
    "\n",
    "examples = [ontonotes[\"test\"][0:1]]\n",
    "print(f\"Processing {len(examples)} examples from the test set.\")\n",
    "\n",
    "for doc in tqdm(examples):\n",
    "    # Fix: Sometimes doc['sentences'] is a list of lists, so we need to flatten it\n",
    "    if isinstance(doc['sentences'], list) and isinstance(doc['sentences'][0], list):\n",
    "        doc['sentences'] = [sentence for sublist in doc['sentences'] for sentence in sublist]\n",
    "    sentences = process_ontonotes_example(doc)\n",
    "    results = await run_always_on(sentences)\n",
    "    results_bio = [(true_bio, list(map(lambda curr: convert_predictions(curr[0], curr[1]), predictions))) for true_bio, predictions in results]\n",
    "    for true_bio, predictions in results_bio:\n",
    "        always_on_metrics.evaluate_metrics(true_bio, predictions)\n",
    "\n",
    "always_on_metrics.save_metrics(\"baselines/always_on_metrics.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd8e7114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics:\n",
      "Total NER invocations: 7474\n",
      "Avg TTFD: 0.11\n",
      "Entity Type          TP         TN         FP (#B-/I-MISC)      FN        \n",
      "----------------------------------------------------------------------\n",
      "O                    N/A        6887       15                   N/A       \n",
      "B-PERSON             0          N/A        20                   4         \n",
      "I-PERSON             0          N/A        12                   3         \n",
      "B-NORP               0          N/A        1 (1/0)              0         \n",
      "I-NORP               0          N/A        0                    0         \n",
      "B-FAC                0          N/A        33                   8         \n",
      "I-FAC                0          N/A        85                   0         \n",
      "B-ORG                8          N/A        2                    7         \n",
      "I-ORG                31         N/A        12                   2         \n",
      "B-GPE                0          N/A        52                   5         \n",
      "I-GPE                0          N/A        11                   1         \n",
      "B-LOC                9          N/A        0                    2         \n",
      "I-LOC                11         N/A        2                    0         \n",
      "B-PRODUCT            0          N/A        0                    0         \n",
      "I-PRODUCT            0          N/A        0                    0         \n",
      "B-DATE               0          N/A        0                    23        \n",
      "I-DATE               0          N/A        0                    13        \n",
      "B-TIME               0          N/A        0                    12        \n",
      "I-TIME               0          N/A        0                    25        \n",
      "B-PERCENT            0          N/A        0                    1         \n",
      "I-PERCENT            0          N/A        0                    1         \n",
      "B-MONEY              0          N/A        0                    0         \n",
      "I-MONEY              0          N/A        0                    0         \n",
      "B-QUANTITY           0          N/A        0                    36        \n",
      "I-QUANTITY           0          N/A        0                    75        \n",
      "B-ORDINAL            0          N/A        0                    15        \n",
      "I-ORDINAL            0          N/A        0                    0         \n",
      "B-CARDINAL           0          N/A        2 (1/0)              33        \n",
      "I-CARDINAL           0          N/A        0                    6         \n",
      "B-EVENT              0          N/A        3 (3/0)              1         \n",
      "I-EVENT              0          N/A        5 (1/4)              0         \n",
      "B-WORK_OF_ART        0          N/A        0                    0         \n",
      "I-WORK_OF_ART        0          N/A        0                    0         \n",
      "B-LAW                0          N/A        0                    0         \n",
      "I-LAW                0          N/A        0                    0         \n",
      "B-LANGUAGE           0          N/A        0                    0         \n",
      "I-LANGUAGE           0          N/A        0                    0         \n",
      "Total                59         6887       255 (6/4)            273       \n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# always_on_metrics = Metrics()\n",
    "# always_on_metrics.load_metrics(\"baselines/always_on_metrics.pkl\")\n",
    "always_on_metrics.print_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc5dc3f",
   "metadata": {},
   "source": [
    "## 6. Optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "533cbc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing all 1200 examples from the test set\n",
      "Batch size: 10\n",
      "Processing mode: Full dataset\n",
      "\n",
      "🚀 Starting processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 120/120 [1:07:11<00:00, 33.59s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Processing complete!\n",
      "Total documents processed: 1200\n",
      "Total errors: 0\n",
      "Metrics saved to: baselines/always_on_metrics_full_1200docs.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Configuration: adjust these for speed vs completeness trade-off\n",
    "SAMPLE_SIZE = 100  # Set to None to process all documents, or a number for sampling\n",
    "BATCH_SIZE = 10    # Process documents in batches to reduce memory usage\n",
    "USE_SAMPLING = False  # Set to False to process all documents\n",
    "\n",
    "# Initialize metrics\n",
    "always_on_metrics = Metrics()\n",
    "\n",
    "# Get test examples with optional sampling\n",
    "test_examples = list(ontonotes[\"test\"])\n",
    "if USE_SAMPLING and SAMPLE_SIZE:\n",
    "    # Use random seed for reproducible sampling\n",
    "    random.seed(42)\n",
    "    test_examples = random.sample(test_examples, min(SAMPLE_SIZE, len(test_examples)))\n",
    "    print(f\"Sampling {len(test_examples)} examples from {len(ontonotes['test'])} total documents\")\n",
    "else:\n",
    "    print(f\"Processing all {len(test_examples)} examples from the test set\")\n",
    "\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Processing mode: {'Sampled' if USE_SAMPLING and SAMPLE_SIZE else 'Full dataset'}\")\n",
    "\n",
    "async def process_single_document_optimized(doc):\n",
    "    \"\"\"Process a single document and return metrics data.\"\"\"\n",
    "    try:\n",
    "        sentences = process_ontonotes_example(doc)\n",
    "        results = await run_always_on(sentences)\n",
    "        results_bio = [(true_bio, list(map(lambda curr: convert_predictions(curr[0], curr[1]), predictions))) \n",
    "                       for true_bio, predictions in results]\n",
    "        return results_bio\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing document: {e}\")\n",
    "        return []\n",
    "\n",
    "async def process_batch_optimized(batch):\n",
    "    \"\"\"Process a batch of documents concurrently.\"\"\"\n",
    "    tasks = [process_single_document_optimized(doc) for doc in batch]\n",
    "    return await asyncio.gather(*tasks, return_exceptions=True)\n",
    "\n",
    "# Run optimized batch processing\n",
    "total_processed = 0\n",
    "total_errors = 0\n",
    "\n",
    "print(f\"\\n🚀 Starting processing...\")\n",
    "\n",
    "for i in tqdm(range(0, len(test_examples), BATCH_SIZE), desc=\"Processing batches\"):\n",
    "    batch = test_examples[i:i+BATCH_SIZE]\n",
    "    batch_results = await process_batch_optimized(batch)\n",
    "    \n",
    "    # Update metrics with batch results\n",
    "    for doc_results in batch_results:\n",
    "        if isinstance(doc_results, Exception):\n",
    "            total_errors += 1\n",
    "            continue\n",
    "        \n",
    "        for true_bio, predictions in doc_results:\n",
    "            always_on_metrics.evaluate_metrics(true_bio, predictions)\n",
    "    \n",
    "    total_processed += len(batch)\n",
    "        \n",
    "\n",
    "print(f\"\\n✅ Processing complete!\")\n",
    "print(f\"Total documents processed: {total_processed}\")\n",
    "print(f\"Total errors: {total_errors}\")\n",
    "\n",
    "# Save metrics\n",
    "metrics_filename = f\"baselines/always_on_metrics_{'sampled' if USE_SAMPLING and SAMPLE_SIZE else 'full'}_{len(test_examples)}docs.pkl\"\n",
    "always_on_metrics.save_metrics(metrics_filename)\n",
    "print(f\"Metrics saved to: {metrics_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04e4a253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALWAYS-ON BASELINE RESULTS\n",
      "========================================\n",
      "Metrics:\n",
      "Total NER invocations: 230118\n",
      "Avg TTFD: 0.44\n",
      "Entity Type          TP         TN         FP (#B-/I-MISC)      FN        \n",
      "----------------------------------------------------------------------\n",
      "O                    N/A        203560     3233                 N/A       \n",
      "B-PERSON             0          N/A        1559 (15/0)          575       \n",
      "I-PERSON             0          N/A        945 (11/13)          567       \n",
      "B-NORP               0          N/A        852 (832/4)          138       \n",
      "I-NORP               0          N/A        149 (54/90)          13        \n",
      "B-FAC                0          N/A        93 (2/0)             56        \n",
      "I-FAC                0          N/A        209 (4/6)            34        \n",
      "B-ORG                1177       N/A        111                  714       \n",
      "I-ORG                1550       N/A        446                  707       \n",
      "B-GPE                0          N/A        2162 (47/2)          384       \n",
      "I-GPE                0          N/A        608 (1/6)            109       \n",
      "B-LOC                141        N/A        7                    67        \n",
      "I-LOC                114        N/A        67                   21        \n",
      "B-PRODUCT            0          N/A        51 (27/3)            39        \n",
      "I-PRODUCT            0          N/A        47 (17/21)           23        \n",
      "B-DATE               0          N/A        7 (5/0)              1780      \n",
      "I-DATE               0          N/A        11 (5/5)             2186      \n",
      "B-TIME               0          N/A        0                    225       \n",
      "I-TIME               0          N/A        2 (2/0)              269       \n",
      "B-PERCENT            0          N/A        0                    408       \n",
      "I-PERCENT            0          N/A        0                    619       \n",
      "B-MONEY              0          N/A        0                    355       \n",
      "I-MONEY              0          N/A        76 (76/0)            699       \n",
      "B-QUANTITY           0          N/A        0                    153       \n",
      "I-QUANTITY           0          N/A        0                    262       \n",
      "B-ORDINAL            0          N/A        1 (1/0)              206       \n",
      "I-ORDINAL            0          N/A        2                    4         \n",
      "B-CARDINAL           0          N/A        9 (4/3)              996       \n",
      "I-CARDINAL           0          N/A        0                    370       \n",
      "B-EVENT              0          N/A        31 (23/0)            54        \n",
      "I-EVENT              0          N/A        113 (30/78)          52        \n",
      "B-WORK_OF_ART        0          N/A        84 (64/0)            85        \n",
      "I-WORK_OF_ART        0          N/A        193 (29/113)         154       \n",
      "B-LAW                0          N/A        11 (11/0)            33        \n",
      "I-LAW                0          N/A        56 (14/34)           62        \n",
      "B-LANGUAGE           0          N/A        22 (20/2)            0         \n",
      "I-LANGUAGE           0          N/A        0                    0         \n",
      "Total                2982       203560     11157 (1294/380)     12419     \n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Print current metrics\n",
    "print(\"ALWAYS-ON BASELINE RESULTS\")\n",
    "print(\"=\"*40)\n",
    "# always_on_metrics = Metrics()\n",
    "# always_on_metrics.load_metrics(\"baselines/always_on_metrics_full_1200.pkl\")\n",
    "always_on_metrics.print_metrics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b31dde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
