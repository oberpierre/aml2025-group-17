{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "701bcd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: staticvectors in ./.venv/lib/python3.13/site-packages (0.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in ./.venv/lib/python3.13/site-packages (from staticvectors) (0.33.0)\n",
      "Requirement already satisfied: numpy>=1.18.4 in ./.venv/lib/python3.13/site-packages (from staticvectors) (2.3.0)\n",
      "Requirement already satisfied: safetensors>=0.4.5 in ./.venv/lib/python3.13/site-packages (from staticvectors) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.48.0 in ./.venv/lib/python3.13/site-packages (from staticvectors) (4.67.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.19.0->staticvectors) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.19.0->staticvectors) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.19.0->staticvectors) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.19.0->staticvectors) (6.0.2)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.19.0->staticvectors) (2.32.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.19.0->staticvectors) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.19.0->staticvectors) (1.1.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests->huggingface-hub>=0.19.0->staticvectors) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests->huggingface-hub>=0.19.0->staticvectors) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests->huggingface-hub>=0.19.0->staticvectors) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests->huggingface-hub>=0.19.0->staticvectors) (2025.6.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install staticvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "015f001f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28673094",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('data/ner_trigger_dataset_validation.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19353d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data keys: KeysView(NpzFile 'data/ner_trigger_dataset_validation.npz' with keys: X, y)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data keys: {data.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "853e8bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (297852, 6)\n",
      "y shape: (297852,)\n",
      "['In' 'the' 'summer' 'of' '2005' ',']\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "X = data['X']\n",
    "y = data['y']\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "\n",
    "print(X[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d49644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v average pooling\n",
    "# w2v max pooling\n",
    "# bert cls token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9132d528",
   "metadata": {},
   "source": [
    "# Embeddings test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "722949c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierre/projects/uzh_repos/aml2025-group-17/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from staticvectors import StaticVectors\n",
    "\n",
    "model = StaticVectors(\"neuml/word2vec/model.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e34c2750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X[0]: ['In' 'the' 'summer' 'of' '2005' ',']\n",
      "Type of X[0]: <class 'numpy.ndarray'>\n",
      "X[0][0]: In\n",
      "Type of X[0][0]: <class 'numpy.str_'>\n"
     ]
    }
   ],
   "source": [
    "print(\"X[0]:\", X[0])\n",
    "print(\"Type of X[0]:\", type(X[0]))\n",
    "print(\"X[0][0]:\", X[0][0])\n",
    "print(\"Type of X[0][0]:\", type(X[0][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "149a5ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297852/297852 [03:04<00:00, 1613.22it/s]\n"
     ]
    }
   ],
   "source": [
    "X_avgpool = []\n",
    "X_maxpool = []\n",
    "\n",
    "for window in tqdm(X):\n",
    "    token_list = window.tolist()\n",
    "\n",
    "    \n",
    "    vectors = [model.embeddings([word])[0] for word in token_list if model.embeddings([word]) is not None]\n",
    "    \n",
    "    if vectors:\n",
    "        avg_vector = np.mean(vectors, axis=0)\n",
    "        max_vector = np.max(vectors, axis=0)\n",
    "    else:\n",
    "        avg_vector = np.zeros(model.dim)\n",
    "        max_vector = np.zeros(model.dim)\n",
    "    \n",
    "    X_avgpool.append(avg_vector)\n",
    "    X_maxpool.append(max_vector)\n",
    "\n",
    "X_avgpool = np.array(X_avgpool)   # shape: (297852, 300)\n",
    "X_maxpool = np.array(X_maxpool)   # shape: (297852, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccbfb1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(297852, 300)\n",
      "(297852, 300)\n"
     ]
    }
   ],
   "source": [
    "print(X_avgpool.shape)\n",
    "# print(X_avgpool[0])\n",
    "print(X_maxpool.shape)\n",
    "# print(X_maxpool[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8739d8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierre/projects/uzh_repos/aml2025-group-17/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "bert_model = AutoModel.from_pretrained(\"dslim/bert-base-NER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "226aa1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.mps.is_available():\n",
    "    device = 'mps'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d261272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.eval()\n",
    "bert_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f6824f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_cls_embeddings_batch(sentence_tokens_list, batch_size=256):\n",
    "    \"\"\"\n",
    "    Get CLS embeddings for a batch of token sequences.\n",
    "    \n",
    "    Args:\n",
    "        sentence_tokens_list: List of token sequences\n",
    "        batch_size: Number of sequences to process at once\n",
    "    \n",
    "    Returns:\n",
    "        numpy array of CLS embeddings\n",
    "    \"\"\"\n",
    "    all_embeddings = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(sentence_tokens_list), batch_size), desc=\"Processing BERT embeddings\"):\n",
    "        batch = sentence_tokens_list[i:i + batch_size]\n",
    "        texts = [\" \".join(tokens) for tokens in batch]\n",
    "        \n",
    "        inputs = tokenizer(texts, return_tensors=\"pt\", truncation=True, \n",
    "                          max_length=512, padding=True).to(device)\n",
    "        outputs = bert_model(**inputs)\n",
    "        cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        \n",
    "        all_embeddings.append(cls_embeddings)\n",
    "    \n",
    "    return np.vstack(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "665903fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing BERT embeddings: 100%|██████████| 9308/9308 [02:40<00:00, 58.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Embedding shape: (297852, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert X to list of token lists for batched processing\n",
    "token_lists = [window.tolist() for window in X]\n",
    "\n",
    "# Use batched processing\n",
    "bert_embeddings = get_cls_embeddings_batch(token_lists, batch_size=32)\n",
    "print(\"BERT Embedding shape:\", bert_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0f6e578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./src/\")\n",
    "from window_slide_model import WindowSlideModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbcd87d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def train_and_eval_pytorch(X, y, name, epochs=3, batch_size=512):\n",
    "    print(f\"\\n Training {name}\")\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "    y_tensor = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Create dataset and split\n",
    "    dataset = TensorDataset(X_tensor, y_tensor)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_ds, test_ds = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size)\n",
    "\n",
    "    # Define model\n",
    "    input_dim = X.shape[1]\n",
    "    model = WindowSlideModel(input_dim).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for xb, yb in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.detach().cpu().item()\n",
    "        print(f\"Epoch {epoch+1}: Loss = {total_loss:.4f}\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_loader:\n",
    "            logits = model(xb)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs > 0.5).int()\n",
    "            all_preds.extend(preds.tolist())\n",
    "            all_labels.extend(yb.int().tolist())\n",
    "\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    \n",
    "    print(f\" Precision: {precision:.4f}\")\n",
    "    print(f\" Recall:    {recall:.4f}\")\n",
    "    print(f\" F1-score:  {f1:.4f}\")\n",
    "    return model, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cfdf08f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training Word2Vec - Avg Pooling\n",
      "Epoch 1: Loss = 200.9151\n",
      "Epoch 1: Loss = 200.9151\n",
      "Epoch 2: Loss = 159.3520\n",
      "Epoch 2: Loss = 159.3520\n",
      "Epoch 3: Loss = 150.9359\n",
      "Epoch 3: Loss = 150.9359\n",
      " Precision: 0.7341\n",
      " Recall:    0.7619\n",
      " F1-score:  0.7477\n",
      "\n",
      " Training Word2Vec - Max Pooling\n",
      " Precision: 0.7341\n",
      " Recall:    0.7619\n",
      " F1-score:  0.7477\n",
      "\n",
      " Training Word2Vec - Max Pooling\n",
      "Epoch 1: Loss = 231.6797\n",
      "Epoch 1: Loss = 231.6797\n",
      "Epoch 2: Loss = 193.5017\n",
      "Epoch 2: Loss = 193.5017\n",
      "Epoch 3: Loss = 188.7371\n",
      "Epoch 3: Loss = 188.7371\n",
      " Precision: 0.6790\n",
      " Recall:    0.5753\n",
      " F1-score:  0.6229\n",
      "\n",
      " Training BERT - CLS Pooling\n",
      " Precision: 0.6790\n",
      " Recall:    0.5753\n",
      " F1-score:  0.6229\n",
      "\n",
      " Training BERT - CLS Pooling\n",
      "Epoch 1: Loss = 182.8686\n",
      "Epoch 1: Loss = 182.8686\n",
      "Epoch 2: Loss = 154.1647\n",
      "Epoch 2: Loss = 154.1647\n",
      "Epoch 3: Loss = 147.3581\n",
      "Epoch 3: Loss = 147.3581\n",
      " Precision: 0.7175\n",
      " Recall:    0.7881\n",
      " F1-score:  0.7511\n",
      " Precision: 0.7175\n",
      " Recall:    0.7881\n",
      " F1-score:  0.7511\n"
     ]
    }
   ],
   "source": [
    "train_and_eval_pytorch(X_avgpool, y, name=\"Word2Vec - Avg Pooling\")\n",
    "train_and_eval_pytorch(X_maxpool, y, name=\"Word2Vec - Max Pooling\")\n",
    "train_and_eval_pytorch(bert_embeddings, y, name=\"BERT - CLS Pooling\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6eefe5",
   "metadata": {},
   "source": [
    "## Training model for approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f698240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (2148223, 768)\n",
      "y shape: (2148223,)\n",
      "[-2.14220770e-03 -1.46557152e-01  8.20886314e-01 -5.50802112e-01\n",
      " -1.86557919e-01 -1.59491926e-01 -5.53287566e-01 -6.91483259e-01\n",
      " -4.10862356e-01 -4.71345186e-01  1.10230744e-01  7.69049168e-01\n",
      "  6.23638749e-01 -3.25382173e-01 -8.74595881e-01 -2.00361326e-01\n",
      "  6.48040652e-01  6.46536052e-02  4.49972570e-01 -2.00347498e-01\n",
      "  9.68802094e-01 -2.54475147e-01  1.10917699e+00  2.05043226e-01\n",
      "  3.03130656e-01 -1.02155015e-01  6.52716339e-01  7.25103557e-01\n",
      "  1.46968469e-01 -4.07497168e-01  3.07938963e-01 -3.11432093e-01\n",
      "  2.23321721e-01  1.51446715e-01 -1.07112598e+00 -3.66511852e-01\n",
      " -4.27757710e-01 -8.20988566e-02  8.21811914e-01 -6.05800927e-01\n",
      " -4.19731081e-01  2.65417576e-01  1.59787774e+00 -1.00400102e+00\n",
      "  5.19288704e-02  7.48898908e-02 -2.02435911e-01 -1.31769925e-01\n",
      " -8.93584043e-02 -1.60512000e-01 -7.22794950e-01  1.58097640e-01\n",
      "  6.56224370e-01 -6.17231965e-01  1.19555938e+00  4.97628003e-01\n",
      "  4.32722658e-01  6.50399745e-01 -2.55437493e-01  1.20980136e-01\n",
      "  3.71183872e-01 -5.49216449e-01  4.67759073e-01 -2.15745255e-01\n",
      " -1.12797223e-01  8.36320996e-01  4.49775845e-01  1.10603130e+00\n",
      " -5.34614325e-01 -1.18344808e+00  3.14535797e-01  1.35370731e+00\n",
      "  1.34481335e+00  9.46739316e-01  1.49473688e-02 -1.02761686e+00\n",
      " -1.17042220e+00  8.67458433e-02 -1.81529954e-01  1.83809534e-01\n",
      " -7.00464845e-02  7.98953772e-01 -1.82699785e-01 -2.78282374e-01\n",
      "  1.56005055e-01 -3.13640833e-01  7.94331312e-01 -1.08770780e-01\n",
      "  7.72332102e-02 -1.13765323e+00  6.28036976e-01 -1.08819976e-01\n",
      " -4.02823240e-01  8.82569002e-04  4.80008096e-01 -6.35274649e-01\n",
      " -2.64859080e-01  1.41522658e+00  6.73366928e+00 -2.12962031e-02\n",
      " -1.98818803e-01 -1.86232328e-01  1.38392746e-01  8.75103235e-01\n",
      "  2.28130728e-01  1.78446576e-01  9.30145800e-01 -7.13413835e-01\n",
      " -1.55765980e-01 -6.35884821e-01  1.06821501e+00  5.47385693e-01\n",
      " -6.75368905e-01 -1.85125560e-01 -2.42448434e-01 -8.22720170e-01\n",
      "  1.25959128e-01 -2.51104683e-01 -4.19753075e-01 -3.58255565e-01\n",
      "  7.61408389e-01 -3.55103612e-01  1.54036713e+00 -8.00107896e-01\n",
      " -7.28956223e-01  3.64279211e-01 -1.14070058e+00 -6.46568060e-01\n",
      "  3.77319902e-01 -4.11781847e-01 -1.45408511e-01  3.55427772e-01\n",
      " -3.70786309e-01  7.00526893e-01  4.68995720e-01  2.67136157e-01\n",
      "  9.14714515e-01 -1.07900575e-01 -2.36973166e-01  1.31362692e-01\n",
      "  4.62240100e-01  1.15583956e-01 -1.77925527e-01  2.74515867e-01\n",
      " -4.84115183e-02  1.80928493e+00  1.60743117e-01  5.85346818e-01\n",
      "  1.14728138e-01  6.60892129e-01  4.31101948e-01  1.60762668e-01\n",
      " -5.95682085e-01 -1.03230178e+00 -5.36835670e-01 -9.27461684e-01\n",
      " -3.53227794e-01  1.80745602e-01  2.34056696e-01 -1.66502327e-01\n",
      " -1.56652248e+00  2.30131358e-01 -3.30801874e-01  3.77613515e-01\n",
      "  1.09730589e+00 -8.02293271e-02  8.13514650e-01 -1.35365856e+00\n",
      "  3.74957211e-02  4.12808448e-01 -2.27045655e-01 -8.19135845e-01\n",
      " -2.24233413e+00  1.50095686e-01  5.43143690e-01  1.55031487e-01\n",
      "  3.07262540e-01 -5.77269912e-01  6.93961382e-02 -7.39454508e-01\n",
      " -1.28122717e-01 -2.18103111e-01  3.40661794e-01  2.99799204e-01\n",
      " -6.25712216e-01 -2.05002114e-01  4.68920946e-01 -4.62565362e-01\n",
      "  1.18198085e+00  7.67299175e-01  2.80730985e-02  4.49916065e-01\n",
      "  4.14951816e-02  2.02263556e-02  2.30442405e-01  8.19827914e-02\n",
      "  1.68701127e-01 -8.14654887e-01 -3.46843183e-01  3.38768184e-01\n",
      " -6.94144487e-01  1.66148946e-01 -4.81802702e-01  7.86051869e-01\n",
      " -1.91864461e-01 -7.38414645e-01 -7.97399938e-01 -5.84776998e-01\n",
      "  5.80788195e-01 -4.14573610e-01 -8.05123389e-01  2.22371951e-01\n",
      "  4.20184843e-02 -3.00199628e-01 -3.25882614e-01 -4.40088302e-01\n",
      " -9.69845951e-01 -9.12048966e-02  6.59225762e-01 -1.17061108e-01\n",
      " -1.09333193e+00  2.89375335e-01  4.59813148e-01 -2.52082497e-01\n",
      "  4.98382859e-02 -2.79060930e-01 -2.67160591e-02 -2.72940367e-01\n",
      "  6.21445775e-01 -5.14003187e-02  2.67773241e-01 -9.72961307e-01\n",
      " -6.76868677e-01  5.51275611e-01  7.01000214e-01 -7.31363356e-01\n",
      " -4.96318787e-01 -2.67076474e-02 -1.82539716e-01  2.29856595e-01\n",
      "  1.12760678e-01 -8.11047912e-01 -6.77589595e-01  4.15963292e-01\n",
      "  1.05281323e-01 -5.31325758e-01  5.39324760e-01 -3.50492522e-02\n",
      " -7.05761090e-02 -1.04389355e-01  3.49894106e-01 -2.90212035e-02\n",
      "  6.34604454e-01 -3.88137758e-01  5.18664300e-01 -7.57139862e-01\n",
      "  1.46816850e-01 -9.37551379e-01 -5.02311647e-01 -1.98622569e-01\n",
      "  5.06927073e-02 -3.31222105e+00  1.11131477e+00 -1.10455416e-01\n",
      "  7.29907006e-02 -5.31340659e-01  2.63090134e-01  6.31657541e-02\n",
      "  6.01084888e-01 -1.33222127e+00 -1.23111975e+00  3.30393076e-01\n",
      " -4.09922689e-01 -8.80196691e-03  1.63707232e+00  8.08726996e-04\n",
      " -9.45747435e-01 -1.13681011e-01 -9.36844051e-01 -1.43325126e+00\n",
      "  2.58378923e-01 -3.43122751e-01 -8.36785376e-01  1.02114213e+00\n",
      "  6.97424114e-01  5.00384271e-01 -2.47059524e-01 -4.52688009e-01\n",
      "  7.92899653e-02  3.17965078e+00  2.05838323e+00 -1.55237466e-01\n",
      " -8.68112922e-01 -2.37199023e-01 -9.65593979e-02  2.46106178e-01\n",
      " -5.81560493e-01  3.01321149e-01 -6.91211879e-01 -1.54859126e-01\n",
      " -1.24702424e-01 -1.09705448e+00 -1.25041401e+00 -7.78175890e-04\n",
      " -5.68966806e-01 -1.36626112e+00 -2.00590163e-01  3.46778810e-01\n",
      " -4.02611434e-01 -1.34297624e-01  2.23432686e-02  1.41148612e-01\n",
      "  2.41583452e-01  1.51968628e-01 -5.36942184e-01  9.97389197e-01\n",
      "  3.37362081e-01 -6.35872185e-02  2.08644599e-01 -1.00007808e+00\n",
      "  5.31657934e-01  1.02557093e-01 -4.56298739e-02 -7.51919806e-01\n",
      "  9.86319542e-01  6.69779852e-02  7.61492014e-01 -5.63790560e-01\n",
      " -8.69837642e-01  2.25431398e-01  6.63282990e-01  1.04412508e+00\n",
      " -4.90301967e-01 -8.93572643e-02 -7.16331527e-02  2.58931041e-01\n",
      "  6.40079603e-02  6.71965599e-01 -9.40616369e-01 -8.71176422e-01\n",
      " -7.17343569e-01  7.38196671e-01 -1.50674909e-01  1.29528403e-01\n",
      "  7.53887072e-02 -4.11834955e-01  7.39685774e-01 -1.85106620e-01\n",
      "  8.15108955e-01  7.09125817e-01  7.05564320e-01  7.16266185e-02\n",
      "  2.28088051e-01  4.34434742e-01 -2.47576252e-01 -6.97685421e-01\n",
      "  2.68851873e-03 -3.75025690e-01 -4.54331338e-02  5.80038726e-01\n",
      "  2.73039751e-02 -2.83612609e+00 -1.13954686e-01 -6.24410570e-01\n",
      "  9.38585460e-01  1.41134895e-02 -1.11603655e-01 -4.52053636e-01\n",
      " -5.09011865e-01  3.41178685e-01  4.70004976e-01  6.40844822e-01\n",
      "  7.92505562e-01  1.16635954e+00  6.02078497e-01 -6.63240314e-01\n",
      " -1.16772562e-01 -4.37396497e-01  1.78466856e-01  2.44021043e-03\n",
      " -5.12674332e-01 -1.62910998e-01 -2.73141742e-01 -5.04448116e-01\n",
      "  9.90968347e-01  1.23043323e+00  1.33029550e-01 -3.10204655e-01\n",
      "  1.50098410e-02  3.52594763e-01  8.14302742e-01 -3.44209045e-01\n",
      "  1.07193625e+00 -9.80036557e-01 -2.73730040e-01 -3.26157868e-01\n",
      " -7.31929660e-01  9.24862742e-01  7.39316285e-01  7.26436436e-01\n",
      " -5.42705894e-01 -6.19806409e-01 -6.74481511e-01 -2.60200948e-01\n",
      " -2.91106626e-02 -3.83590996e-01 -1.73726559e-01 -3.73333961e-01\n",
      " -1.30034864e+00  4.48201984e-01 -6.12984657e-01 -1.69942051e-01\n",
      "  3.34738612e-01  1.73854679e-01 -8.75711143e-02  7.56937027e-01\n",
      "  1.23563677e-01 -2.14938134e-01  3.80913645e-01  1.10805023e+00\n",
      " -1.38675737e+00 -2.15536416e-01 -7.04915106e-01 -8.48447621e-01\n",
      " -5.25129199e-01  1.39699742e-01 -4.00037766e-01 -2.93444097e-02\n",
      "  1.15515761e-01 -4.44470078e-01 -8.19930792e-01 -4.88407671e-01\n",
      "  9.93860513e-02  2.27830410e-01 -8.47235918e-01 -1.53765392e+00\n",
      "  7.72088408e-01 -1.54212141e+00 -5.07609621e-02  4.38939953e+00\n",
      " -4.50779468e-01 -1.86166167e-01 -2.86466241e-01 -1.00283611e+00\n",
      "  1.72563240e-01 -4.35267776e-01 -4.05612797e-01  1.18162262e+00\n",
      "  5.91193795e-01 -5.11693239e-01 -2.40238518e-01  8.53574991e-01\n",
      "  2.76377350e-01  3.63129467e-01  8.18859458e-01  7.88967848e-01\n",
      "  1.05110228e+00 -8.25639367e-01  2.07461223e-01 -1.31942242e-01\n",
      "  5.52028537e-01  6.18714750e-01 -4.37023163e-01 -1.01101136e+00\n",
      "  1.93794817e-01 -9.30404246e-01  6.03968024e-01 -6.57373607e-01\n",
      " -7.60047436e-02 -1.07053268e+00  2.78619260e-01  1.42511356e+00\n",
      "  5.14189899e-01  6.90381408e-01 -5.30249655e-01  5.00586033e-01\n",
      "  7.83283591e-01  3.47504199e-01 -6.85619950e-01 -5.07351756e-01\n",
      " -9.78268623e-01  1.05839515e+00  4.18366343e-01  4.48668867e-01\n",
      " -5.89859605e-01 -3.80730540e-01 -1.10016234e-01  9.44810569e-01\n",
      "  5.48327863e-01 -7.70965517e-02 -6.29056990e-01 -1.17680609e+00\n",
      " -1.57588378e-01 -1.78493038e-01 -5.08480072e-01  1.22303292e-01\n",
      " -2.67203003e-01 -5.21807909e-01 -7.09825382e-02 -2.08934277e-01\n",
      " -5.98289013e-01  9.76254821e-01  4.58078206e-01 -3.06488782e-01\n",
      " -7.40623653e-01 -6.87956333e-01 -6.22159541e-01 -4.53765303e-01\n",
      "  6.56725615e-02 -1.11190784e+00  2.12156087e-01 -1.92992017e-01\n",
      "  5.45705020e-01  1.22383013e-01 -5.44959426e-01 -8.41629267e-01\n",
      "  1.23619631e-01 -5.33830881e-01 -1.25667560e+00 -4.38003927e-01\n",
      " -8.49195063e-01 -1.18063724e+00 -2.11524904e-01  8.05201948e-01\n",
      "  6.68501616e-01 -9.12814200e-01 -1.17397702e+00 -5.78402936e-01\n",
      " -2.04846099e-01  3.04936260e-01 -1.49425244e+00  6.41828656e-01\n",
      "  9.64564860e-01 -6.44656301e-01 -5.84965706e-01  4.42562491e-01\n",
      "  6.62616074e-01  9.98079658e-01 -5.06625652e-01  7.71114677e-02\n",
      "  8.64595950e-01 -7.91946709e-01  8.93319398e-02  1.93607062e-01\n",
      " -1.25177646e+00  5.95897615e-01 -6.98774636e-01  3.14646214e-02\n",
      " -3.44436198e-01  6.51683092e-01 -1.88172549e-01  1.19976556e+00\n",
      " -5.10409236e-01 -4.56014216e-01  5.81349015e-01 -1.05652189e+00\n",
      "  3.59954536e-01 -2.06964040e+00 -2.32983604e-02  1.22231543e+00\n",
      " -3.76619190e-01  8.60798284e-02 -4.62820172e-01 -4.17130649e-01\n",
      "  1.67915851e-01 -2.07346871e-01  1.05299675e+00  2.27437168e-01\n",
      "  5.59447408e-01 -2.02324319e+00 -3.77055615e-01 -2.44437993e-01\n",
      "  7.96550572e-01  5.60680211e-01 -1.57499886e+00 -8.56185377e-01\n",
      "  1.69718906e-01 -3.93427610e-02  9.23151255e-01  6.97850406e-01\n",
      "  4.39045608e-01  2.08205849e-01  7.30866969e-01 -2.23026678e-01\n",
      " -5.44090569e-01 -4.14485782e-01 -6.28746152e-01  1.98065251e-01\n",
      " -5.28569877e-01  1.16492486e+00  3.53706121e-01  1.06910942e-02\n",
      " -1.50226510e+00 -9.13414538e-01 -2.41149530e-01  1.90868706e-01\n",
      " -7.63010800e-01  5.34937739e-01  4.18972254e-01  5.90750575e-01\n",
      " -2.41204113e-01 -9.50435758e-01 -2.32441276e-02  4.36966002e-01\n",
      " -1.83817494e+00  2.95786858e-01 -1.33965358e-01 -1.24653709e+00\n",
      "  8.12530339e-01 -2.49105543e-01  6.16055012e-01 -7.25667119e-01\n",
      "  9.96740237e-02 -5.53980529e-01  2.86330521e-01  2.69617140e-01\n",
      " -1.86801702e-03  5.41513622e-01  3.41850042e-01 -1.11671396e-01\n",
      " -3.78045768e-01  4.95470792e-01 -1.84741005e-01 -6.03535652e-01\n",
      " -4.37310547e-01 -3.37743133e-01 -2.72306621e-01  5.44344783e-02\n",
      "  1.31540668e+00 -3.97865415e-01  1.55560958e+00 -2.22030748e-02\n",
      "  4.47863430e-01  5.32300353e-01 -6.70475483e-01  1.80808604e-02\n",
      " -2.66924202e-01 -2.05262959e-01 -4.38354343e-01 -7.37560332e-01\n",
      "  9.76870298e-01 -3.36183608e-01  1.07445097e+00 -8.30338001e-02\n",
      " -5.81757009e-01 -2.53082067e-03  6.33592308e-02  5.13117015e-01\n",
      " -4.45445001e-01 -7.99804389e-01 -3.04398328e-01  1.79271474e-01\n",
      "  5.93001880e-02  7.33602822e-01 -4.39874172e-01 -9.01097000e-01\n",
      " -4.91332524e-02  3.72749209e-01  9.27143395e-01  3.60058367e-01\n",
      " -7.26220310e-01 -9.20831978e-01  4.36818868e-01  2.00491309e+00\n",
      " -1.21286444e-01 -5.93499601e-01 -5.12045920e-01 -2.92560130e-01\n",
      " -2.62628734e-01 -1.10044694e+00 -5.53571641e-01  1.77508557e+00\n",
      " -4.91084993e-01  2.35812873e-01  6.83754504e-01 -4.12914120e-02\n",
      "  5.91800213e-01 -3.90445799e-01  1.43595111e+00 -4.97578561e-01\n",
      "  3.42850357e-01  3.12527061e-01  1.37370601e-01 -1.47971064e-01\n",
      " -8.30783784e-01  8.84413004e-01 -6.49989471e-02  5.49100041e-01\n",
      "  5.87177813e-01  5.06244063e-01 -1.21191335e+00  6.68701708e-01\n",
      " -1.26636696e+00 -2.43271708e-01 -4.09438670e-01  2.53655910e-02\n",
      "  1.00239885e+00 -1.09164249e-02 -8.65072548e-01 -8.29835013e-02\n",
      "  3.19060422e-02  4.01258439e-01 -1.19159293e+00  2.02834517e-01\n",
      "  7.46995866e-01 -3.68276179e-01  1.30939806e+00  1.07296240e+00\n",
      "  5.54380834e-01 -2.84582853e-01 -2.91318059e-01  8.05426002e-01\n",
      " -6.10504448e-01  5.16617954e-01  4.54171658e-01 -1.27288592e+00\n",
      "  3.97604078e-01 -6.31491661e-01  6.49491608e-01 -2.96770930e-01\n",
      "  4.09851074e-01 -4.38619435e-01  8.76102030e-01  8.89733583e-02\n",
      " -5.69704294e-01  2.05412716e-01 -3.35720658e-01  1.37642995e-02\n",
      " -4.15465176e-01  4.10379916e-01 -2.23667905e-01 -1.10425383e-01\n",
      " -3.66074681e-01  4.79543656e-02  5.71268380e-01 -1.14029634e+00\n",
      "  7.35805273e-01  3.49824280e-01 -5.63386559e-01  2.70959556e-01\n",
      "  1.62113726e-01  6.56786084e-01  3.92456651e-01  8.39444458e-01\n",
      "  6.15016222e-01 -4.48544443e-01  1.69051623e+00 -7.17086136e-01\n",
      "  9.11919400e-02  8.90043855e-01 -1.93356961e-01  9.05543387e-01\n",
      "  1.24538928e-01  7.15982020e-01 -8.06049109e-01 -7.17914402e-01\n",
      "  7.07671821e-01 -3.84848595e-01  1.25693715e+00  6.35653198e-01\n",
      " -9.03305590e-01  3.64483416e-01 -6.51510000e-01  7.79844597e-02\n",
      " -3.89585108e-01  4.00245860e-02  4.13632751e-01  2.69765705e-01]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "data = np.load('data/ner_trigger_dataset_embeddings.npz')\n",
    "X, y = data['X'], data['y']\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "\n",
    "print(X[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "37177323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training BERT - CLS Pooling\n",
      "Epoch 1: Loss = 2007.2094\n",
      "Epoch 2: Loss = 1810.6204\n",
      "Epoch 3: Loss = 1751.5439\n",
      "Epoch 4: Loss = 1712.2786\n",
      "Epoch 5: Loss = 1688.4551\n",
      "Epoch 6: Loss = 1667.4398\n",
      "Epoch 7: Loss = 1648.9284\n",
      "Epoch 8: Loss = 1634.2220\n",
      "Epoch 9: Loss = 1623.6756\n",
      "Epoch 10: Loss = 1616.3725\n",
      "Epoch 11: Loss = 1605.7175\n",
      "Epoch 12: Loss = 1596.6743\n",
      "Epoch 13: Loss = 1590.2830\n",
      "Epoch 14: Loss = 1583.8722\n",
      "Epoch 15: Loss = 1578.0360\n",
      "Epoch 16: Loss = 1574.1797\n",
      "Epoch 17: Loss = 1568.8902\n",
      "Epoch 18: Loss = 1562.2486\n",
      "Epoch 19: Loss = 1559.7728\n",
      "Epoch 20: Loss = 1554.4390\n",
      " Precision: 0.7831\n",
      " Recall:    0.7957\n",
      " F1-score:  0.7893\n"
     ]
    }
   ],
   "source": [
    "model, _, _, _ = train_and_eval_pytorch(X, y, name=\"BERT - CLS Pooling\", epochs=20, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "510f1884",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"models/bert_cls_pooling_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b4498d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat shape: tensor([0.0953], device='mps:0', grad_fn=<SqueezeBackward1>), tensor([0.5238], device='mps:0', grad_fn=<SigmoidBackward0>), probs: tensor([1], device='mps:0', dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "model = WindowSlideModel(X.shape[1])\n",
    "model.load_state_dict(torch.load(\"models/bert_cls_pooling_model.pkl\", weights_only=True))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# find ix where y is 1\n",
    "ix = np.where(y == 1)[0][1]\n",
    "y_hat = model(torch.tensor(X[ix], dtype=torch.float32).to(device).unsqueeze(0))\n",
    "probs = (torch.sigmoid(y_hat) > 0.5).int()\n",
    "print(f\"y_hat shape: {y_hat}, {torch.sigmoid(y_hat)}, probs: {probs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bae09f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
