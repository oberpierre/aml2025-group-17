{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25fd52eb",
   "metadata": {},
   "source": [
    "# Window size model (approach 2) Baseline\n",
    "\n",
    "This notebook implements the sliding window baseline for near real-time Named Entity Recognition (NER)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cba6621",
   "metadata": {},
   "source": [
    "## 1. Setup and preparation\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "10251243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in ./.venv/lib/python3.13/site-packages (3.6.0)\n",
      "Requirement already satisfied: transformers in ./.venv/lib/python3.13/site-packages (4.52.4)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.13/site-packages (from datasets) (2.3.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./.venv/lib/python3.13/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.venv/lib/python3.13/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.13/site-packages (from datasets) (2.3.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in ./.venv/lib/python3.13/site-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./.venv/lib/python3.13/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in ./.venv/lib/python3.13/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./.venv/lib/python3.13/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in ./.venv/lib/python3.13/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in ./.venv/lib/python3.13/site-packages (from datasets) (0.33.0)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.13/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.13/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./.venv/lib/python3.13/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.13/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.13/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.24.0->datasets) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.5.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in ./.venv/lib/python3.13/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (2025.6.15)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8765cd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "06be2391",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"src\")\n",
    "from utils import convert_ids_to_bio, convert_predictions\n",
    "from window_slide_model import WindowSlideModel\n",
    "from metrics import Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "140516b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import metrics\n",
    "reload(metrics)\n",
    "from metrics import Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e88fc4",
   "metadata": {},
   "source": [
    "## 2. Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "50050e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded with splits: dict_keys(['train', 'validation', 'test'])\n"
     ]
    }
   ],
   "source": [
    "# Load the English portion of OntoNotes 5.0\n",
    "ontonotes = load_dataset(\n",
    "    \"conll2012_ontonotesv5\",\n",
    "    \"english_v12\",\n",
    "    cache_dir=\"./dataset/ontonotes\",\n",
    ")\n",
    "print(f\"Dataset loaded with splits: {ontonotes.keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3999e2c",
   "metadata": {},
   "source": [
    "## 3. Creating all window sizes of size 6 accross test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "02e7d071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 183876\n",
      "Example window: [['Aha', ',', 'aha', '.']], BIO: ['O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "num_windows = 0\n",
    "windows = []\n",
    "SPAN_LENGTH = 6\n",
    "\n",
    "# Iterate through the test split\n",
    "for doc in ontonotes[\"test\"]:\n",
    "    # Fix: Sometimes doc['sentences'] is a list of lists, so we need to flatten it\n",
    "    if isinstance(doc['sentences'], list) and isinstance(doc['sentences'][0], list):\n",
    "        doc['sentences'] = [sentence for sublist in doc['sentences'] for sentence in sublist]\n",
    "    for sentence in doc[\"sentences\"]:\n",
    "        curr_window = []\n",
    "        bio_tags = convert_ids_to_bio(sentence['named_entities'])\n",
    "        sentence_windows = []\n",
    "        for idx, word in enumerate(sentence['words']):\n",
    "            curr_window.append(word)\n",
    "            # If the current window reaches the defined span length, add it to the list\n",
    "            if len(curr_window) == SPAN_LENGTH:\n",
    "                sentence_windows.append(curr_window.copy())\n",
    "                # Slide the window by one position\n",
    "                curr_window = curr_window[1:]\n",
    "                num_windows += 1\n",
    "\n",
    "        if len(curr_window) < SPAN_LENGTH:  # If there are remaining words in the current window\n",
    "            sentence_windows.append(curr_window.copy())\n",
    "            num_windows += 1\n",
    "\n",
    "        windows.append((bio_tags, sentence_windows))\n",
    "\n",
    "print(f\"Total windows created: {num_windows}\")\n",
    "ix = random.randint(0, len(windows) - 1)\n",
    "print(f\"Example window: {windows[ix][1]}, BIO: {windows[ix][0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f4a1d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "bert_model = AutoModel.from_pretrained(\"dslim/bert-base-NER\")\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.mps.is_available():\n",
    "    device = 'mps'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "bert_model.to(device)\n",
    "bert_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ed84caf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12217/12217 [00:00<00:00, 2750204.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows to process: 183876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_windows = []\n",
    "for _, sentence_windows in tqdm(windows):\n",
    "    all_windows.extend(sentence_windows)\n",
    "\n",
    "print(f\"Total windows to process: {len(all_windows)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c569a2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing CLS token for windows: 100%|██████████| 1437/1437 [01:39<00:00, 14.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# Calculate all embeddings for the windows in a batch-wise manner\n",
    "batch_size = 128  # Adjust batch size based on your GPU memory\n",
    "embeddings = []\n",
    "for i in tqdm(range(0, len(all_windows), batch_size), desc=\"Computing CLS token for windows\"):\n",
    "    batch = all_windows[i:i + batch_size]\n",
    "    inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, is_split_into_words=True)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    \n",
    "    cls_token = outputs.last_hidden_state[:, 0, :]\n",
    "    embeddings.append(cls_token.cpu().numpy())\n",
    "\n",
    "embeddings = np.concatenate(embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fb145508",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"data/ner_trigger_dataset_test_embeddings_sentences.npz\", embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6d2f1f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embeddings: (183876, 768)\n"
     ]
    }
   ],
   "source": [
    "data = np.load(\"data/ner_trigger_dataset_test_embeddings_sentences.npz\")\n",
    "embeddings = data['embeddings']\n",
    "print(f\"Shape of embeddings: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b240cf8",
   "metadata": {},
   "source": [
    "## 4. Implementing sliding window baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c0df97f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowSlideModel(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_model = WindowSlideModel(embeddings.shape[1])\n",
    "window_model.load_state_dict(torch.load(\"models/bert_cls_pooling_model.pkl\", weights_only=True))\n",
    "window_model.to(device)\n",
    "window_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e960247d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting BIO tags: 100%|██████████| 1437/1437 [00:00<00:00, 1827.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of predictions: (183876,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Determining invocation times\n",
    "batch_size = 128  # Adjust batch size based on your GPU memory\n",
    "y_hat = []\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0, len(embeddings), batch_size), desc=\"Predicting BIO tags\"):\n",
    "        cls_token = torch.tensor(embeddings[i:i + batch_size]).to(device)\n",
    "        logits = window_model(cls_token)\n",
    "        y_hat_batch = (torch.sigmoid(logits) > 0.5).int()  # Convert logits to binary predictions\n",
    "\n",
    "        y_hat.append(y_hat_batch.cpu().numpy())\n",
    "\n",
    "# unbatch of y_hat\n",
    "y_hat = np.concatenate(y_hat, axis=0)\n",
    "print(f\"Shape of predictions: {y_hat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d98aa273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of invocations: 43404\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of invocations: {np.sum(y_hat)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753e5676",
   "metadata": {},
   "source": [
    "## 5. Evaludating sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "11bb2c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "\n",
    "ner_tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "ner_model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "ner_model.eval()\n",
    "ner_model.to(device)\n",
    "ner_pipeline = pipeline(\"ner\", model=ner_model, tokenizer=ner_tokenizer, aggregation_strategy=\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a3e6900c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating sliding window metrics: 100%|██████████| 12217/12217 [05:42<00:00, 35.71it/s] \n"
     ]
    }
   ],
   "source": [
    "sliding_window_metrics = Metrics()\n",
    "\n",
    "ix = 0\n",
    "for bio_tags, sentence_windows in tqdm(windows, desc=\"Evaluating sliding window metrics\"):\n",
    "    invocations = []\n",
    "    sentence_window_offsets = 0\n",
    "    prev_ix = ix\n",
    "    for window in sentence_windows:\n",
    "        if y_hat[ix] == 1:\n",
    "            results = ner_pipeline(\" \".join(window))\n",
    "            pred_bio_tags = convert_predictions(window, results)\n",
    "            current_invocation = invocations[-1].copy() if len(invocations) > 0 else []\n",
    "            # previous windows overlap at 5 positions with the current window\n",
    "            target_current_invocation_length = sentence_window_offsets + len(window)\n",
    "            while len(current_invocation) < target_current_invocation_length:\n",
    "                current_invocation.append(\"O\")\n",
    "\n",
    "            # overwrite the end of current_invocation with the new predictions\n",
    "            current_invocation[sentence_window_offsets:sentence_window_offsets + len(pred_bio_tags)] = pred_bio_tags\n",
    "            invocations.append(current_invocation)\n",
    "\n",
    "        sentence_window_offsets += 1\n",
    "        ix += 1\n",
    "\n",
    "\n",
    "    sliding_window_metrics.evaluate_metrics(([], bio_tags), invocations)\n",
    "\n",
    "sliding_window_metrics.save_metrics(\"baseline/sliding_window_metrics.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d7d71010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics:\n",
      "Total NER invocations: 43404\n",
      "Avg TTFD: 1.33\n",
      "FPR@FNR: 0.0647@0.7210\n",
      "Entity Type          TP         TN         FP (#B-/I-MISC)      FN        \n",
      "----------------------------------------------------------------------\n",
      "O                    N/A        97327      1802                 N/A       \n",
      "B-PERSON             1409       N/A        47                   678       \n",
      "I-PERSON             428        N/A        432                  652       \n",
      "B-NORP               0          N/A        843 (826/0)          147       \n",
      "I-NORP               0          N/A        144 (106/33)         18        \n",
      "B-FAC                0          N/A        87 (1/0)             62        \n",
      "I-FAC                0          N/A        196 (3/2)            47        \n",
      "B-ORG                1058       N/A        122                  822       \n",
      "I-ORG                952        N/A        825                  926       \n",
      "B-GPE                0          N/A        2095 (29/0)          451       \n",
      "I-GPE                0          N/A        596 (4/1)            121       \n",
      "B-LOC                133        N/A        7                    75        \n",
      "I-LOC                76         N/A        94                   32        \n",
      "B-PRODUCT            0          N/A        41 (13/0)            49        \n",
      "I-PRODUCT            0          N/A        34 (5/4)             36        \n",
      "B-DATE               0          N/A        5 (4/0)              1782      \n",
      "I-DATE               0          N/A        7 (5/0)              2190      \n",
      "B-TIME               0          N/A        0                    225       \n",
      "I-TIME               0          N/A        2 (2/0)              269       \n",
      "B-PERCENT            0          N/A        0                    408       \n",
      "I-PERCENT            0          N/A        0                    619       \n",
      "B-MONEY              0          N/A        0                    355       \n",
      "I-MONEY              0          N/A        76 (61/0)            699       \n",
      "B-QUANTITY           0          N/A        0                    153       \n",
      "I-QUANTITY           0          N/A        0                    262       \n",
      "B-ORDINAL            0          N/A        0                    207       \n",
      "I-ORDINAL            0          N/A        2                    4         \n",
      "B-CARDINAL           0          N/A        1 (1/0)              1004      \n",
      "I-CARDINAL           0          N/A        0                    370       \n",
      "B-EVENT              0          N/A        21 (11/0)            64        \n",
      "I-EVENT              0          N/A        80 (28/36)           85        \n",
      "B-WORK_OF_ART        0          N/A        55 (27/0)            114       \n",
      "I-WORK_OF_ART        0          N/A        116 (22/39)          231       \n",
      "B-LAW                0          N/A        10 (8/0)             34        \n",
      "I-LAW                0          N/A        50 (14/24)           68        \n",
      "B-LANGUAGE           0          N/A        19 (18/1)            3         \n",
      "I-LANGUAGE           0          N/A        0                    0         \n",
      "Total                4056       97327      7809 (1188/140)      13262     \n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# sliding_window_metrics = Metrics()\n",
    "# sliding_window_metrics.load_metrics(\"baseline/sliding_window_metrics.pkl\")\n",
    "sliding_window_metrics.print_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "943053be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average prefix tokens: 8 tokens * 183876 windows\n",
      "Average invocation tokens: 8 tokens * 43404 invocations\n",
      "Total FLOPs for sliding window model: 125,249,513,445,672\n"
     ]
    }
   ],
   "source": [
    "from flops_calculator import FlopsCalculator\n",
    "flops_calculator = FlopsCalculator(\"baselines/flops_coefficients.pkl\")\n",
    "\n",
    "num_windows = len(y_hat)\n",
    "num_invocations = np.sum(y_hat)\n",
    "avg_tokens = 8 # window of 6 words + 2 for [CLS] and [SEP]\n",
    "\n",
    "print(f\"Average prefix tokens: {avg_tokens} tokens * {num_windows} windows\")\n",
    "print(f\"Average invocation tokens: {avg_tokens} tokens * {num_invocations} invocations\")\n",
    "\n",
    "sliding_window_flops = flops_calculator.calculate_flops(\"model_2\", avg_tokens) * num_windows\n",
    "ner_running_flops = flops_calculator.calculate_flops(\"ner\", avg_tokens) * num_invocations\n",
    "\n",
    "total_flops = sliding_window_flops + ner_running_flops\n",
    "print(f\"Total FLOPs for sliding window model: {sliding_window_flops:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aee1280",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
